{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import shutil\n",
    "import trainer\n",
    "import ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Video potential:\n",
    "import kagglehub\n",
    "#Download latest version\n",
    "data_path  = \"./data/potholes_video\"\n",
    "# create a directory to store the dataset\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "kaggle_path = kagglehub.dataset_download(\"gracehephzibahm/pothole-severity-classification\")\n",
    "shutil.move(kaggle_path, data_path)\n",
    "\n",
    "# move the video file to the data folder\n",
    "shutil.move(data_path + \"/1/Challenge Track 2_ Pothole severity classification via computer vision/sections.mov\", data_path + \"/sections.mov\")\n",
    "\n",
    "# remove the old directory\n",
    "shutil.rmtree(data_path + \"/1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_video_by_width(input_video_path, output_video_path, target_width=448):\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video stream or file\")\n",
    "        return\n",
    "    \n",
    "    # Get the width and height of the video\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Calculate the aspect ratio\n",
    "    scale_factor = target_width / original_width\n",
    "    target_height = int(original_height * scale_factor)\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (target_width, target_height))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Resize the frame\n",
    "        resized_frame = cv2.resize(frame, (target_width, target_height))\n",
    "        \n",
    "        # Write the resized frame\n",
    "        out.write(resized_frame)\n",
    "    \n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(\"Resized video saved at\", output_video_path)\n",
    "    \n",
    "    \n",
    "def resize_video_by_height(input_video_path, output_video_path, target_height=448):\n",
    "    # Open the input video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video.\")\n",
    "        return\n",
    "\n",
    "    # Get original video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Calculate scaling factor and target width to maintain aspect ratio\n",
    "    scale_factor = target_height / original_height\n",
    "    target_width = int(original_width * scale_factor)\n",
    "\n",
    "    # Video writer setup\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (target_width, target_height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize the frame\n",
    "        resized_frame = cv2.resize(frame, (target_width, target_height))\n",
    "\n",
    "        # Write the resized frame to the output video\n",
    "        out.write(resized_frame)\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Resized video saved as: {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For matplotlib RGB:\n",
    "colors_rgb = {\n",
    "    'minor_pothole': (0,128,1),   #008001 GREEN\n",
    "    'medium_pothole': (255,166,0),  #ffa500 ORANGE\n",
    "    'major_pothole': (229,0,0)      #e50000 RED\n",
    "}\n",
    "\n",
    "# For CV2 BGR:\n",
    "colors_bgr = {\n",
    "    'minor_pothole': (1,128,0),   #008001 GREEN\n",
    "    'medium_pothole': (0,166,255),  #ffa500 ORANGE\n",
    "    'major_pothole': (0,0,229)      #e50000 RED\n",
    "}\n",
    "\n",
    "\n",
    "def video_inference(input_video_path, output_video_path, model_name, model_path, without_severity_levels=False):\n",
    "    if model_name == 'YOLO':\n",
    "        model = YOLO(model_path)\n",
    "    elif model_name == 'FASTERRCNN':\n",
    "        if without_severity_levels is False:\n",
    "            model = trainer.get_model(model_name=\"fasterrcnn_resnet50_fpn\", with_severity_levels=True)\n",
    "        else:\n",
    "            model = trainer.get_model(model_name=\"fasterrcnn_resnet50_fpn\", with_severity_levels=False)\n",
    "        state_dict = torch.load(model_path, weights_only=True)\n",
    "        model.load_state_dict(state_dict)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)  # Move the model to the GPU\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "    else:\n",
    "        raise ValueError(f\"Model name '{model_name}' is not supported. Please use 'YOLO' or 'FASTERRCNN'.\")\n",
    "\n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Run YOLO with streaming\n",
    "    if model_name == 'YOLO':\n",
    "        for result in model.predict(source=input_video_path, stream=True, conf=0.25, verbose=False):\n",
    "            frame = result.orig_img.copy()  # Start with the original frame\n",
    "            for box in result.boxes:\n",
    "                # Extract bounding box and label information\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "                confidence = box.conf[0]\n",
    "                label = box.cls[0]\n",
    "                class_name = model.names[int(label)]\n",
    "\n",
    "                # Set color for the class\n",
    "                color = colors_bgr.get(class_name, (255, 255, 255))  # Default to white if not found\n",
    "\n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "                # Draw label and confidence\n",
    "                label_text = f\"{class_name} {confidence:.2f}\"\n",
    "                (text_width, text_height), baseline = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "                cv2.rectangle(frame, (x1, y1 - text_height - baseline), (x1 + text_width, y1), color, -1)\n",
    "                cv2.putText(frame, label_text, (x1, y1 - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "            out.write(frame)  # Save frame to output video\n",
    "\n",
    "    else:  # Faster R-CNN inference\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # Prepare image for Faster R-CNN\n",
    "            # Convert BGR to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Convert to tensor and normalize\n",
    "            image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "            # Add batch dimension\n",
    "            image_tensor = image_tensor.unsqueeze(0)\n",
    "            image_tensor = image_tensor.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                predictions = model(image_tensor)\n",
    "\n",
    "            # Process predictions\n",
    "            boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "            labels = predictions[0]['labels'].cpu().numpy()\n",
    "            scores = predictions[0]['scores'].cpu().numpy()\n",
    "\n",
    "            # Filter predictions based on confidence threshold\n",
    "            confidence_threshold = 0.5\n",
    "            mask = scores > confidence_threshold\n",
    "            boxes = boxes[mask]\n",
    "            labels = labels[mask]\n",
    "            scores = scores[mask]\n",
    "\n",
    "            # Draw predictions on frame\n",
    "            for box, label, score in zip(boxes, labels, scores):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                \n",
    "                if without_severity_levels:\n",
    "                    # Determine color based on label\n",
    "                    if label == 1:\n",
    "                        color = colors_bgr['major_pothole']\n",
    "                        severity = 'Pothole'\n",
    "                else:\n",
    "                    # Determine color based on severity level\n",
    "                    if label == 1:  # Minor pothole\n",
    "                        color = colors_bgr['minor_pothole']\n",
    "                        severity = 'Minor'\n",
    "                    elif label == 2:  # Medium pothole\n",
    "                        color = colors_bgr['medium_pothole']\n",
    "                        severity = 'Medium'\n",
    "                    else:  # Major pothole\n",
    "                        color = colors_bgr['major_pothole']\n",
    "                        severity = 'Major'\n",
    "\n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Add label with confidence score\n",
    "                label_text = f'{severity}: {score:.2f}'\n",
    "                label_size, baseline = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "                y1_label = max(y1, label_size[1])\n",
    "                cv2.rectangle(frame, (x1, y1_label - label_size[1] - baseline),\n",
    "                            (x1 + label_size[0], y1_label), color, cv2.FILLED)\n",
    "                cv2.putText(frame, label_text, (x1, y1_label - baseline),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "            # Write frame to output video\n",
    "            out.write(frame)\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Processed video saved as: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed video saved as: ./data/potholes_video/pothole_70mph_vid_yolo.mp4\n"
     ]
    }
   ],
   "source": [
    "#input_video_path = data_path + \"/sections.mov\"\n",
    "#output_video_path = data_path + \"/sections_yolo.mp4\"\n",
    "input_video_path = data_path + \"/pothole_70mph_vid.mp4\"\n",
    "output_video_path = data_path + \"/pothole_70mph_vid_yolo.mp4\"\n",
    "# input_video_path = data_path + \"/potholes_at_night_vid.mp4\"\n",
    "# output_video_path = data_path + \"/potholes_at_night_vid_yolo.mp4\"\n",
    "\n",
    "\n",
    "# Run video inference with YOLO\n",
    "video_inference(input_video_path, output_video_path, model_name='YOLO', model_path='data/models/yolov8m/runs/yolov8m_severity_train_aug/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized video saved at ./data/potholes_video/sections_resized.mp4\n"
     ]
    }
   ],
   "source": [
    "input_video_path = data_path + \"/sections.mov\"\n",
    "resized_video_path = data_path + \"/sections_resized.mp4\"\n",
    "resize_video_by_width(input_video_path=input_video_path, output_video_path=resized_video_path, target_width=448)\n",
    "#resize_video_by_height(input_video_path=input_video_path, output_video_path=resized_video_path, target_height=448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed video saved as: ./data/potholes_video/sections_fasterrcnn_severities.mp4\n"
     ]
    }
   ],
   "source": [
    "output_video_path = data_path + \"/sections_fasterrcnn_severities.mp4\"\n",
    "#output_video_path = data_path + \"/pothole_70mph_vid_fasterrcnn.mp4\"\n",
    "\n",
    "#output_video_path = data_path + \"/potholes_at_night_vid_fasterrcnn.mp4\"\\\n",
    "#model_path = 'data/models/fasterrcnn_resnet50_fpn/fasterrcnn_resnet50_fpn_best.pth'\n",
    "model_path = 'data/models/fasterrcnn_resnet_severity/fasterrcnn_resnet50_fpn_best.pth'\n",
    "video_inference(resized_video_path, output_video_path, model_name='FASTERRCNN', model_path=model_path, without_severity_levels=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
